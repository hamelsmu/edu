{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29116dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import torchvision.models as tvmodels\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "\n",
    "import params\n",
    "from utils import get_predictions, create_iou_table, MIOU, BackgroundIOU, \\\n",
    "                  RoadIOU, TrafficLightIOU, TrafficSignIOU, PersonIOU, VehicleIOU, BicycleIOU, t_or_f, display_diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff6b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = SimpleNamespace(\n",
    "    framework=\"fastai\",\n",
    "    img_size=180, #(180, 320) in 16:9 proportions,\n",
    "    batch_size=8, #8 keep small in Colab to be manageable\n",
    "    augment=True, # use data augmentation\n",
    "    epochs=1, # for brevity, increase for better results :)\n",
    "    lr=2e-3,\n",
    "    pretrained=True,  # whether to use pretrained encoder,\n",
    "    mixed_precision=True, # use automatic mixed precision\n",
    "    arch=\"resnet18\",\n",
    "    seed=42,\n",
    "    log_preds=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954c2bb4-4d69-4dc4-9653-26cbc13ba509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    processed_data_at = wandb.use_artifact(f'{params.PROCESSED_DATA_AT}:latest')\n",
    "    processed_dataset_dir = Path(processed_data_at.download())\n",
    "    return processed_dataset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ae3d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(fname):\n",
    "    return (fname.parent.parent/\"labels\")/f\"{fname.stem}_mask.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0010b696-eb6a-402e-9d3e-98c20a7deb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(processed_dataset_dir, is_test=False):\n",
    "    df = pd.read_csv(processed_dataset_dir / 'data_split.csv')\n",
    "    \n",
    "    if not is_test:\n",
    "        df = df[df.Stage != 'test'].reset_index(drop=True)\n",
    "        df['is_valid'] = df.Stage == 'valid'\n",
    "    else:\n",
    "        df = df[df.Stage == 'test'].reset_index(drop=True)\n",
    "        \n",
    "    \n",
    "    # assign paths\n",
    "    df[\"image_fname\"] = [processed_dataset_dir/f'images/{f}.jpg' for f in df.File_Name.values]\n",
    "    df[\"label_fname\"] = [label_func(f) for f in df.image_fname.values]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4268334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df, bs=4, img_size=(180, 320), augment=True):\n",
    "    block = DataBlock(blocks=(ImageBlock, MaskBlock(codes=params.BDD_CLASSES)),\n",
    "                  get_x=ColReader(\"image_fname\"),\n",
    "                  get_y=ColReader(\"label_fname\"),\n",
    "                  splitter=ColSplitter(),\n",
    "                  item_tfms=Resize(img_size),\n",
    "                  batch_tfms=aug_transforms() if augment else None,\n",
    "                 )\n",
    "    return block.dataloaders(df, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387dc2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_predictions(learn):\n",
    "    \"Log a Table with model predictions\"\n",
    "    samples, outputs, predictions = get_predictions(learn)\n",
    "    table = create_iou_table(samples, outputs, predictions, params.BDD_CLASSES)\n",
    "    wandb.log({\"pred_table\":table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ec120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_metrics(learn):\n",
    "    scores = learn.validate()\n",
    "    metric_names = ['final_loss'] + [f'final_{x.name}' for x in learn.metrics]\n",
    "    final_results = {metric_names[i] : scores[i] for i in range(len(scores))}\n",
    "    for k,v in final_results.items(): \n",
    "        wandb.summary[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dd39ae-3b74-4c72-bb83-02e0ad68a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_learner(learn, run):\n",
    "    art = wandb.Artifact('learner', type=\"fastai learner\")\n",
    "    with art.new_file('fastai_model.pkl') as f:\n",
    "        learn.export(f.name)\n",
    "    run.log_artifact(art)\n",
    "        \n",
    "def save_dls(dls, run, nm='train'):\n",
    "    torch.save(dls, f'{nm}-dataloader.pkl')\n",
    "    art = wandb.Artifact(f'{nm}_dls', type=\"fastai dataloaders\")\n",
    "    art.add_file(f'{nm}-dataloader.pkl')\n",
    "    run.log_artifact(art)\n",
    "\n",
    "    \n",
    "def train(config):\n",
    "    set_seed(config.seed)\n",
    "    with wandb.init(project=params.WANDB_PROJECT, entity=params.ENTITY, job_type=\"training\", config=config) as run:\n",
    "        \n",
    "        # good practice to inject params using sweeps\n",
    "        config = wandb.config\n",
    "        \n",
    "        # prepare data\n",
    "        processed_dataset_dir = download_data()\n",
    "        proc_df = get_df(processed_dataset_dir)\n",
    "        dls = get_data(proc_df, bs=config.batch_size, img_size=config.img_size, augment=config.augment)\n",
    "        save_dls(dls, run)\n",
    "        \n",
    "        metrics = [MIOU(), BackgroundIOU(), RoadIOU(), TrafficLightIOU(),\n",
    "                   TrafficSignIOU(), PersonIOU(), VehicleIOU(), BicycleIOU()]\n",
    "        \n",
    "        cbs = [WandbCallback(log_preds=False, log_model=True), \n",
    "               SaveModelCallback(monitor='miou'),] + ([MixedPrecision()] if config.mixed_precision else [])\n",
    "        \n",
    "        learn = unet_learner(dls, arch=getattr(tvmodels, config.arch), pretrained=config.pretrained, \n",
    "                             metrics=metrics)\n",
    "        \n",
    "        learn.fit_one_cycle(config.epochs, config.lr, cbs=cbs)\n",
    "        if config.log_preds:\n",
    "            log_predictions(learn)\n",
    "        final_metrics(learn)\n",
    "        _, disp = display_diagnostics(learner=learn, return_vals=True)\n",
    "        wandb.log({\"confusion matrix\": disp.figure_})\n",
    "        save_learner(learn, run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a8eaf3-a416-442d-b5c3-6e8a2bcf7b55",
   "metadata": {},
   "source": [
    "## Run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a789d6-ca7b-4709-9370-d36ae60d2c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a400096-7a4c-49fa-82a3-eaef0bdd0aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
